{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv()\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2,api_key=tavily_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: create tools for the agent to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph=StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_model)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\",\n",
    "                                    self.exists_action,\n",
    "                                    {True: \"action\", False: END})   \n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph=graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model= model.bind_tools(tools)\n",
    "\n",
    "    def call_model(self, state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message=self.model.invoke(messages)\n",
    "        return {'messages':[message]}\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result=state[\"messages\"][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "    \n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls=state[\"messages\"][-1].tool_calls\n",
    "        results=[]\n",
    "        for t in tool_calls:\n",
    "            print(f\"calling tool : {t}\")\n",
    "            result = self.tools[t['name']].invoke(t[\"args\"])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'],name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model\")\n",
    "        return {'messages':results}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs\n",
    "\n",
    "- [ ] **_Task 1:_** change the prompt to analyze logs\n",
    "- [ ] **_Task 2:_** Implement function Y\n",
    "- [ ] **_Task 3:_** Test the implementation of Z\n",
    "\n",
    "Remember to **_update_** this list as tasks are completed or new tasks arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a log analysis assistant. Your task is to analyze the provided JSON logs and extract meaningful insights. For each log entry, identify and summarize key details, including the event type, user actions, system warnings, and errors. Highlight any patterns or notable incidents.\n",
    "\"\"\"\n",
    "\n",
    "user_message_template_str = \"\"\"\n",
    "Here are the logs:\n",
    "\n",
    "{logs}\n",
    "\n",
    "Tasks:\n",
    "1. **User Activities**: Summarize the actions performed by each user.\n",
    "2. **System Warnings and Errors**: Identify and explain any warnings and errors logged.\n",
    "3. **Patterns and Anomalies**: Highlight any patterns or unusual activities observed in the logs.\n",
    "\n",
    "Output Format:\n",
    "Provide a structured summary with sections for User Activities, System Warnings and Errors, and Patterns and Anomalies.\n",
    "\"\"\"\n",
    "user_message_template = PromptTemplate(input_variables=[\"logs\"], template=user_message_template_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### reading logs json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/logs.json\",\"r\") as f:\n",
    "    logs = json.load(f)\n",
    "\n",
    "logs_json = json.dumps(logs, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = user_message_template.format(logs=logs_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=google_api_key, verbose=True)\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(model, [], system=system_message, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=user_message)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stream thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "# for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "#     for v in event.values():\n",
    "#         print(v['messages'])\n",
    "\n",
    "result= abot.graph.invoke({\"messages\":messages },\n",
    "                     config = {\"configurable\":{\"thread_id\": \"4\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis=result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Log Analysis Summary\n",
       "\n",
       "### User Activities\n",
       "\n",
       "**John Doe:**\n",
       "* Logged in at 12:34:56Z with session ID \"abc123\" from IP 192.168.1.10.\n",
       "* Attempted to read \"/restricted/financial_report.xlsx\" but was denied due to permission issues.\n",
       "* Successfully read \"/public/annual_report.pdf\".\n",
       "* Logged out at 12:37:22Z after a session duration of 146 seconds.\n",
       "\n",
       "**Jane Smith:**\n",
       "* Logged in at 12:45:00Z with session ID \"def456\" from IP 192.168.1.15.\n",
       "* Successfully wrote to \"/public/sales_data.csv\".\n",
       "* Logged out at 12:55:10Z after a session duration of 310 seconds.\n",
       "\n",
       "### System Warnings and Errors\n",
       "\n",
       "**Errors:**\n",
       "* At 12:35:01Z, user \"john_doe\" was denied access to \"/restricted/financial_report.xlsx\" due to \"Permission Denied\".\n",
       "* At 12:50:00Z, a \"System Error\" occurred with error code 500 and message \"Internal Server Error\" in the \"Authentication Service\".\n",
       "\n",
       "**Warnings:**\n",
       "* At 12:36:15Z, the system logged a warning about high resource utilization with CPU usage at 85% and memory usage at 70%.\n",
       "\n",
       "### Patterns and Anomalies\n",
       "\n",
       "* **Unauthorized Access Attempt:** John Doe attempted to access a restricted file (\"/restricted/financial_report.xlsx\"), which was denied. This indicates a potential security concern and requires further investigation.\n",
       "* **High Resource Utilization:** The system warning at 12:36:15Z indicates a potential performance bottleneck. It's important to investigate the cause of high CPU and memory usage to ensure system stability.\n",
       "* **System Error:** The \"Internal Server Error\" in the Authentication Service at 12:50:00Z suggests a possible bug or configuration issue. This error needs immediate attention to restore proper authentication functionality.\n",
       "* **User Access Patterns:** Both users accessed public files. John Doe attempted to access a restricted file, indicating a potential security breach, while Jane Smith only accessed public files. This requires further analysis to understand the context of their actions.\n",
       "\n",
       "**Further Investigation:**\n",
       "\n",
       "* The \"Permission Denied\" error for John Doe accessing the restricted file should be investigated to determine if it was a legitimate attempt or a potential security breach.\n",
       "* The \"Internal Server Error\" in the Authentication Service requires immediate attention and debugging to determine the root cause and prevent future occurrences.\n",
       "* The high resource utilization should be investigated to identify the processes or services responsible and implement necessary optimizations.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Async thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [HumanMessage(content=\"What is the weather in Casablanca?\")]\n",
    "# thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "# async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "#     kind = event[\"event\"]\n",
    "#     if kind == \"on_chat_model_stream\":\n",
    "#         content = event[\"data\"][\"chunk\"].content\n",
    "#         if content:\n",
    "#             # Empty content in the context of OpenAI means\n",
    "#             # that the model is asking for a tool to be invoked.\n",
    "#             # So we only print non-empty content\n",
    "#             print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
