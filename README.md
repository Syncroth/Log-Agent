This project aims to develop an efficient log analysis system using Apache Kafka, Apache Spark, a Large Language Model (LLM), and a vector database. Log streams are ingested in real-time through Kafka, which acts as the message broker. Apache Spark processes these logs, performing necessary transformations and aggregations. Once a day, a sampling module extracts a representative sample of the processed log data for analysis by the LLM. The LLM analyzes this sample to uncover patterns, generate insights, and identify potential issues. These insights are then vectorized and stored in a vector database, creating a knowledge base for efficient future retrieval and queries. This system provides real-time monitoring and deep analytical capabilities, ensuring proactive issue detection and continuous improvement of system performance and security.
